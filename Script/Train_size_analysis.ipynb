{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bursty Train Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "#-----------------------------IMPORTANT-------------------------------------------\n",
    "### VERY IMPORTANT: Changing the path from library to library2 change the folder of original results\n",
    "import sys\n",
    "sys.path.insert(0, '../Script/library3/')\n",
    "\n",
    "from utilities import *\n",
    "from randomization import *\n",
    "from burst_func import *\n",
    "import networkx as nx\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def burst_train(inter_ev,dt):\n",
    "    ev_distr = np.zeros(len(inter_ev))\n",
    "    i = 0\n",
    "    \n",
    "    cnt = Counter()\n",
    "    d = 0\n",
    "    c = 1\n",
    "    ev_distr[0] = d\n",
    "    while i < len(inter_ev):\n",
    "        \n",
    "        \n",
    "        if inter_ev[i]<= dt:\n",
    "            \n",
    "            ev_distr[i+1] = d\n",
    "            c+=1\n",
    "            \n",
    "            i +=1\n",
    "    \n",
    "        else:\n",
    "            \n",
    "            cnt.update(Counter([c]))\n",
    "            \n",
    "            d +=1\n",
    "            \n",
    "            if i<len(inter_ev)-1:ev_distr[i+1] = d\n",
    "            \n",
    "            i+=1\n",
    "            c = 1\n",
    "            \n",
    "            continue\n",
    "    assert (sum([k*v for k,v in cnt.items()]) == np.sum([k*v for k,v in Counter(Counter(ev_distr).values()).items()]))\n",
    "    return cnt,ev_distr\n",
    "\n",
    "\n",
    "def get_burst_train(df,dt):\n",
    "    \n",
    "    df_rest = df.copy()\n",
    "    int_ev_time = [x for x in (df_rest.timestamp.shift(-1) - df_rest.timestamp).values if ((x!= np.nan))]\n",
    "    b_train = burst_train(int_ev_time,dt)[0]\n",
    "    bursts = burst_train(int_ev_time,dt)[1]\n",
    "    df['burst'] = bursts\n",
    "    return Counter(b_train),df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Trains of egonetwork activity time series for Randomized reference models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_bursty_trains_rand(df,line_graph,dt_list,seed,title1):\n",
    "    \n",
    "    burst_cnt_G1_link_tot = {}\n",
    "    \n",
    "    burst_cnt_G1_ego_tot = {}\n",
    "    burst_cnt_G2_ego_tot = {}\n",
    "    burst_cnt_G3_ego_tot = {}\n",
    "\n",
    "\n",
    "    n_links_cnt_G1_ego_tot = {}\n",
    "    n_links_cnt_G2_ego_tot = {}\n",
    "    n_links_cnt_G3_ego_tot = {}\n",
    "\n",
    "    df_G1 = permute_timestamps(df,seed)    ### timestamp reshuffle\n",
    "    df_G2 = shuffle_df(df,seed)               ### timeseries reshuffle\n",
    "    df_G3 = random_df_same_weight(df,seed)  ### timeseries reshuffle with same n contacts\n",
    "    for dt in dt_list:\n",
    "\n",
    "        burst_cnt_G1_link_dt = Counter()\n",
    "\n",
    "        burst_cnt_G1_ego_dt = Counter()\n",
    "        burst_cnt_G2_ego_dt = Counter()\n",
    "        burst_cnt_G3_ego_dt = Counter()\n",
    "\n",
    "        n_links_cnt_G1_ego_dt = Counter()\n",
    "        n_links_cnt_G2_ego_dt = Counter()\n",
    "        n_links_cnt_G3_ego_dt = Counter()\n",
    "\n",
    "        for nodes in tqdm(df_G1.nodes.unique()):\n",
    "\n",
    "                neigh_set = (set(list(nx.neighbors(line_graph,nodes)))|set([nodes]))\n",
    "\n",
    "                df_G1_link = df_G1[df_G1.nodes == nodes]\n",
    "\n",
    "                df_G1_ego = df_G1[df_G1.nodes.isin(neigh_set)] ### timestamp reshuffle\n",
    "                df_G2_ego = df_G2[df_G2.nodes.isin(neigh_set)]   ### timeseries reshuffle\n",
    "                df_G3_ego = df_G3[df_G3.nodes.isin(neigh_set)] ### timeseries reshuffle with same n contacts\n",
    "\n",
    "\n",
    "\n",
    "                brst_cnt_G1_ego,df_G1_ego = get_burst_train(df_G1_ego,dt) ### timestamp reshuffle\n",
    "                brst_cnt_G2_ego,df_G2_ego = get_burst_train(df_G2_ego,dt) ### timeseries reshuffle\n",
    "                brst_cnt_G3_ego,df_G3_ego = get_burst_train(df_G3_ego,dt) ### timeseries reshuffle with same n contacts\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                burst_cnt_G1_link_dt.update(get_burst_train(df_G1_link,dt=dt)[0])\n",
    "                burst_cnt_G1_ego_dt.update(brst_cnt_G1_ego)    ### timestamp reshuffle\n",
    "                burst_cnt_G2_ego_dt.update(brst_cnt_G2_ego)       ### timeseries reshuffle\n",
    "                burst_cnt_G3_ego_dt.update(brst_cnt_G3_ego)   ### timeseries reshuffle with same n contacts\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                n_links_cnt_G1_ego_dt.update((Counter(df_G1_ego.groupby('burst')['nodes'].apply(lambda x:(float(len(set(x))),float(len(list(x))))).values)))\n",
    "                n_links_cnt_G2_ego_dt.update((Counter(df_G2_ego.groupby('burst')['nodes'].apply(lambda x:(float(len(set(x))),float(len(list(x))))).values)))\n",
    "                n_links_cnt_G3_ego_dt.update((Counter(df_G3_ego.groupby('burst')['nodes'].apply(lambda x:(float(len(set(x))),float(len(list(x))))).values)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        burst_cnt_G1_link_tot[title1+str(dt)] = burst_cnt_G1_link_dt\n",
    "        burst_cnt_G1_ego_tot[title1+str(dt)] = burst_cnt_G1_ego_dt      ### timestamp reshuffle\n",
    "        burst_cnt_G2_ego_tot[title1+str(dt)] = burst_cnt_G2_ego_dt  ### timeseries reshuffle\n",
    "        burst_cnt_G3_ego_tot[title1+str(dt)] = burst_cnt_G3_ego_dt   ### timeseries reshuffle with same n contacts\n",
    "\n",
    "\n",
    "        n_links_cnt_G1_ego_tot[title1+str(dt)] = n_links_cnt_G1_ego_dt                  ### timestamp reshuffle\n",
    "\n",
    "        n_links_cnt_G2_ego_tot[title1+str(dt)] = n_links_cnt_G2_ego_dt            ### timeseries reshuffle\n",
    "        n_links_cnt_G3_ego_tot[title1+str(dt)] = n_links_cnt_G3_ego_dt            ### timeseries reshuffle with same n contacts\n",
    "\n",
    "        ### oreder: timeseries reshuffle, single, timestamp reshuffle, timeseries reshuffle with same n contacts\n",
    "        file_2_save = map(lambda x: x[title1+str(dt)],[burst_cnt_G2_ego_tot,burst_cnt_G1_link_tot,burst_cnt_G1_ego_tot,burst_cnt_G3_ego_tot])\n",
    "        ### oreder: timeseries reshuffle, timestamp reshuffle, timeseries reshuffle with same n contacts\n",
    "        file_2_save_link = map(lambda x: x[title1+str(dt)],[n_links_cnt_G2_ego_tot,n_links_cnt_G1_ego_tot,n_links_cnt_G3_ego_tot])\n",
    "\n",
    "        try: os.mkdir('../Results/Bursty_trains/'+title1+'rand/')\n",
    "        except: print '../Results/Bursty_trains/'+title1+'rand/'\n",
    "       \n",
    "        title_burst_cnt = '../Results/Bursty_trains/'+title1+'rand/'+title1+'_'+str(dt)+'_'+str(seed)\n",
    "        #assert file_2_save == joblib.load(a+'.joblib')\n",
    "        joblib.dump(file_2_save,title_burst_cnt+'.joblib')\n",
    "\n",
    "        title_link_cnt = '../Results/Bursty_trains/'+title1+'rand/'+title1+'_n_links_'+str(dt)+'_'+str(seed)\n",
    "        #assert file_2_save_link == joblib.load(b+'.joblib')\n",
    "        joblib.dump(file_2_save_link,title_link_cnt+'.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Trains of egonetwork activity timer series for Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_bursty_trains_data(df,line_graph,dt_list,title1, save = False):\n",
    "    burst_cnt_G_link_tot = {}\n",
    "    brst_cnt_G_ego_tot = {}\n",
    "\n",
    "    n_links_cnt_G_ego_tot = {}\n",
    "    \n",
    "    #    if title1 !='tij_lnVS':continue\n",
    "    for dt in dt_list:\n",
    "        burst_cnt_G_link_dt = Counter()\n",
    "        brst_cnt_G_ego_dt = Counter()\n",
    "\n",
    "        n_links_cnt_G_ego_dt = Counter()\n",
    "        \n",
    "        k = 0\n",
    "        for nodes in tqdm(df.nodes.unique()):\n",
    "\n",
    "            neigh_set = (set(list(nx.neighbors(g,nodes)))|set([nodes]))\n",
    "            df_G_link = df[df.nodes == nodes]\n",
    "            df_G_ego = df[df.nodes.isin(neigh_set)]                    ### data\n",
    "\n",
    "\n",
    "\n",
    "            brst_cnt_G_ego,df_G_ego = get_burst_train(df_G_ego,dt)\n",
    "            \n",
    "            burst_cnt_G_link_dt.update(get_burst_train(df_G_link,dt)[0])\n",
    "            brst_cnt_G_ego_dt.update(brst_cnt_G_ego)               ### data\n",
    "            n_links_cnt_G_ego_dt.update((Counter(df_G_ego.groupby('burst')['nodes'].apply(lambda x:(float(len(set(x))),float(len(list(x))))).values)))\n",
    "\n",
    "            k += 1\n",
    "\n",
    "        burst_cnt_G_link_tot[title1+str(dt)] = burst_cnt_G_link_dt\n",
    "        brst_cnt_G_ego_tot[title1+str(dt)] = brst_cnt_G_ego_dt         ### data\n",
    "        n_links_cnt_G_ego_tot[title1+str(dt)] = n_links_cnt_G_ego_dt\n",
    "        \n",
    "\n",
    "        file_2_save = map(lambda x: x[title1+str(dt)],[burst_cnt_G_link_tot,brst_cnt_G_ego_tot])\n",
    "        file_2_save_link = map(lambda x: x[title1+str(dt)],[n_links_cnt_G_ego_tot,n_link_rand_orig_neigh_burst1])\n",
    "\n",
    "\n",
    "        try: os.mkdir('../Results/Bursty_trains/'+title1+'/')\n",
    "        except: print '../Results/Bursty_trains/'+title1+'/'\n",
    "       \n",
    "        title_burst_cnt = '../Results/Bursty_trains/'+title1+'/'+title1+'_'+str(dt)\n",
    "        #assert file_2_save == joblib.load(a+'.joblib')\n",
    "        joblib.dump(file_2_save,a+'.joblib')\n",
    "\n",
    "        title_link_cnt = '../Results/Bursty_trains/'+title1+'/'+title1+'_n_links_'+str(dt)\n",
    "        #assert file_2_save_link == joblib.load(b+'.joblib')\n",
    "        joblib.dump(file_2_save_link,b+'.joblib')\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Trains for time series of activity of top 10% most active links for Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def compute_bursty_trains_most_active(df,line_graph,dt_list,title1,most_active = 0.1): \n",
    "    for dt in dt_list:\n",
    "\n",
    "        cnt_tot = {}\n",
    "        link_cnt_tot = {}\n",
    "        most_active_links = df.groupby(df.nodes).size().sort_values(ascending = False)[:int(float(len(g.nodes))*most_active)].index\n",
    "        link_weights = df.groupby(df.nodes).size()\n",
    "        ### include all links with weight w>=w_min\n",
    "        w_min = link_weights.sort_values(ascending = False)[:int(float(len(g.nodes))*0.1)].iloc[-1]\n",
    "        most_active_links = node_rank[node_rank>=minimum_value].index\n",
    "\n",
    "\n",
    "        cnt_n = Counter()\n",
    "        cnt1_n_links = Counter()\n",
    "\n",
    "\n",
    "\n",
    "        k = 0\n",
    "        for nodes in tqdm(most_active_links):\n",
    "\n",
    "\n",
    "            df_rest_most_active_links = df[df.nodes == nodes]   \n",
    "\n",
    "\n",
    "            brst_cnt_most_active_links,df_rest_most_active_links = get_burst_train(df_rest_most_active_links,dt)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            cnt_n.update(brst_cnt_neigh)               ### data\n",
    "\n",
    "\n",
    "\n",
    "        cnt_tot[title1] = cnt_n\n",
    "        try:os.mkdir('../Results/Bursty_trains_most_active/')\n",
    "        except: print 'folder already existing'\n",
    "        #assert cnt_tot == joblib.load('../Results/Bursty_trains_most_active/'+title1+'_'+str(dt)+'.joblib')       \n",
    "        joblib.dump(cnt_tot,'../Results/Bursty_trains_most_active/'+title1+'_'+str(dt)+'.joblib')       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/755 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/albertoceria/anaconda/lib/python2.7/site-packages/ipykernel_launcher.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "100%|██████████| 755/755 [04:34<00:00,  2.75it/s]\n",
      "  0%|          | 0/755 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Results/Bursty_trains/tij_lnVSrand/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 755/755 [03:54<00:00,  3.22it/s]\n",
      "  0%|          | 0/755 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Results/Bursty_trains/tij_lnVSrand/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 755/755 [03:29<00:00,  3.60it/s]\n",
      "  0%|          | 0/755 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Results/Bursty_trains/tij_lnVSrand/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 755/755 [03:10<00:00,  3.96it/s]\n",
      "  0%|          | 0/755 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Results/Bursty_trains/tij_lnVSrand/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 755/755 [02:56<00:00,  4.28it/s]\n",
      "  0%|          | 0/755 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Results/Bursty_trains/tij_lnVSrand/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 755/755 [02:45<00:00,  4.55it/s]\n",
      "  0%|          | 0/755 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Results/Bursty_trains/tij_lnVSrand/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 755/755 [02:39<00:00,  4.74it/s]\n",
      "  0%|          | 0/755 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Results/Bursty_trains/tij_lnVSrand/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 755/755 [01:35<00:00,  7.94it/s]\n",
      "  0%|          | 1/755 [00:00<01:22,  9.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Results/Bursty_trains/tij_lnVS/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 755/755 [01:31<00:00,  8.27it/s]\n",
      "  0%|          | 1/755 [00:00<01:21,  9.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Results/Bursty_trains/tij_lnVS/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 755/755 [01:27<00:00,  8.66it/s]\n",
      "  0%|          | 1/755 [00:00<01:19,  9.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Results/Bursty_trains/tij_lnVS/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 755/755 [01:23<00:00,  8.99it/s]\n",
      "  0%|          | 1/755 [00:00<01:38,  7.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Results/Bursty_trains/tij_lnVS/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 755/755 [01:21<00:00,  9.31it/s]\n",
      "  0%|          | 0/755 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Results/Bursty_trains/tij_lnVS/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 755/755 [01:19<00:00,  9.50it/s]\n",
      "  0%|          | 0/755 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Results/Bursty_trains/tij_lnVS/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 755/755 [01:17<00:00,  9.78it/s]\n",
      "  3%|▎         | 2/78 [00:00<00:04, 18.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Results/Bursty_trains/tij_lnVS/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:03<00:00, 19.86it/s]\n",
      "  3%|▎         | 2/78 [00:00<00:04, 18.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder already existing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:03<00:00, 20.02it/s]\n",
      "  3%|▎         | 2/78 [00:00<00:04, 18.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder already existing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:03<00:00, 19.93it/s]\n",
      "  3%|▎         | 2/78 [00:00<00:03, 19.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder already existing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:03<00:00, 20.18it/s]\n",
      "  3%|▎         | 2/78 [00:00<00:04, 17.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder already existing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:03<00:00, 19.90it/s]\n",
      "  4%|▍         | 3/78 [00:00<00:03, 20.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder already existing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:03<00:00, 20.37it/s]\n",
      "  3%|▎         | 2/78 [00:00<00:04, 18.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder already existing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:04<00:00, 18.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder already existing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "seed = 1\n",
    "dt_list = [60,120,300,600,1200,2400,3600]\n",
    "print seed\n",
    "\n",
    "\n",
    "title1 = 'tij_lnVS'\n",
    "df = get_df(title1)\n",
    "g = get_linegraph(title1)\n",
    "    \n",
    "compute_bursty_trains_rand(df,g,dt_list,seed,title1)\n",
    "\n",
    "compute_bursty_trains_data(df,g,dt_list,title1)\n",
    "\n",
    "compute_bursty_trains_most_active(df,g,dt_list,title1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
