{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bursty Train Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "#-----------------------------IMPORTANT-------------------------------------------\n",
    "### VERY IMPORTANT: Changing the path from library to library2 change the folder of original results\n",
    "import sys\n",
    "sys.path.insert(0, '../Script/library3/')\n",
    "\n",
    "from utilities import *\n",
    "from randomization import *\n",
    "from burst_func import *\n",
    "import networkx as nx\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def burst_train(inter_ev, dt):\n",
    "    \"\"\"\n",
    "    Calculate burst train statistics from a list of inter-event times.\n",
    "\n",
    "    Args:\n",
    "        inter_ev (list): List of inter-event times.\n",
    "        dt (float): Time interval for burst detection.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing burst counts and burst distribution.\n",
    "    \"\"\"\n",
    "    ev_distr = np.zeros(len(inter_ev))\n",
    "    i = 0\n",
    "\n",
    "    cnt = Counter()\n",
    "    d = 0\n",
    "    c = 1\n",
    "    ev_distr[0] = d\n",
    "    \n",
    "    while i < len(inter_ev):\n",
    "        if inter_ev[i] <= dt:\n",
    "            ev_distr[i + 1] = d\n",
    "            c += 1\n",
    "            i += 1\n",
    "        else:\n",
    "            cnt.update(Counter([c]))\n",
    "            d += 1\n",
    "            if i < len(inter_ev) - 1:\n",
    "                ev_distr[i + 1] = d\n",
    "            i += 1\n",
    "            c = 1\n",
    "            continue\n",
    "    \n",
    "    # Assert that the burst counts match the burst distribution sum\n",
    "    assert (sum([k * v for k, v in cnt.items()]) == np.sum([k * v for k, v in Counter(Counter(ev_distr).values()).items()]))\n",
    "    \n",
    "    return cnt, ev_distr\n",
    "\n",
    "def get_burst_train(df, dt):\n",
    "    \"\"\"\n",
    "    Calculate burst train statistics for a DataFrame of events.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): DataFrame containing event data.\n",
    "        dt (float): Time interval for burst detection.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing burst counts and the modified DataFrame with burst information.\n",
    "    \"\"\"\n",
    "    df_rest = df.copy()\n",
    "    int_ev_time = [x for x in (df_rest.timestamp.shift(-1) - df_rest.timestamp).values if ((x != np.nan))]\n",
    "    b_train = burst_train(int_ev_time, dt)[0]\n",
    "    bursts = burst_train(int_ev_time, dt)[1]\n",
    "    df['burst'] = np.array(bursts)\n",
    "    \n",
    "    return Counter(b_train), df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Trains of egonetwork activity time series for Randomized reference models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bursty_trains(df, line_graph, dt_list, graph_list, seed, title1, include_single_link_burst=False, reproduce_paper=False):\n",
    "    \"\"\"\n",
    "    Calculate bursty trains for a given DataFrame and save the results.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): Input DataFrame containing temporal network data.\n",
    "        line_graph (Graph): Graph representing the network.\n",
    "        dt_list (list): List of time intervals to consider.\n",
    "        graph_list (list): List of graphs to use in computations (e.g., ['G'], ['G1', 'G2', 'G3']).\n",
    "        seed (int): Random seed for shuffling data.\n",
    "        title1 (str): Title for the results.\n",
    "        include_single_link_burst (bool): Include burst counts for single links.\n",
    "        reproduce_paper (bool): Reproduce the paper's results.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the computed bursty trains.\n",
    "    \"\"\"\n",
    "    # Check assertions based on the input parameters\n",
    "    assert graph_list\n",
    "    if reproduce_paper:\n",
    "        assert (graph_list == ['G']) or (graph_list == ['G1', 'G2', 'G3'])\n",
    "        assert include_single_link_burst\n",
    "\n",
    "    # Initialize dictionaries to store the results\n",
    "    overall_dictionary = dict()\n",
    "    df_dictionary = dict()\n",
    "\n",
    "    # Loop through the graph list and initialize sub-dictionaries\n",
    "    for k in graph_list:\n",
    "        overall_dictionary[k] = dict()\n",
    "        if include_single_link_burst:\n",
    "            overall_dictionary[k]['burst_cnt_link'] = dict()\n",
    "        overall_dictionary[k]['burst_cnt_ego'] = dict()\n",
    "        overall_dictionary[k]['n_link_cnt'] = dict()\n",
    "\n",
    "        # Create a copy of the DataFrame for each graph type\n",
    "        if k == 'G':\n",
    "            df_dictionary[k] = df.copy()\n",
    "        elif k == 'G1':\n",
    "            df_dictionary[k] = permute_timestamps(df, seed)  # Timestamp reshuffle\n",
    "        elif k == 'G2':\n",
    "            df_dictionary[k] = shuffle_df(df, seed)  # Time series reshuffle\n",
    "        elif k == 'G3':\n",
    "            df_dictionary[k] = random_df_same_weight(df, seed)  # Time series reshuffle with same n contacts\n",
    "\n",
    "    # Loop through the specified time intervals\n",
    "    for dt in dt_list:\n",
    "        dt_dictionary = dict()\n",
    "\n",
    "        # Loop through the graph list for each time interval\n",
    "        for k in graph_list:\n",
    "            dt_dictionary[k] = dict()\n",
    "            if include_single_link_burst:\n",
    "                dt_dictionary[k]['burst_cnt_link'] = Counter()\n",
    "            dt_dictionary[k]['burst_cnt_ego'] = Counter()\n",
    "            dt_dictionary[k]['n_link_cnt'] = Counter()\n",
    "\n",
    "        # Iterate through unique nodes in the network\n",
    "        for nodes in tqdm(df.nodes.unique()):\n",
    "            neigh_set = (set(list(nx.neighbors(line_graph, nodes))) | set([nodes]))\n",
    "\n",
    "            # Loop through the graph list for each node\n",
    "            for k in graph_list:\n",
    "                df_graph = df_dictionary[k]\n",
    "\n",
    "                if include_single_link_burst:\n",
    "                    df_link = df_graph[df_graph.nodes == nodes]\n",
    "                    brst_cnt_link, _ = get_burst_train(df_link, dt)\n",
    "                    dt_dictionary[k]['burst_cnt_link'].update(brst_cnt_link)\n",
    "\n",
    "                df_ego = df_graph[df_graph.nodes.isin(neigh_set)]\n",
    "                brst_cnt_ego, df_ego = get_burst_train(df_ego, dt)\n",
    "                dt_dictionary[k]['burst_cnt_ego'].update(brst_cnt_ego)\n",
    "\n",
    "                cnt_n_links_per_train = Counter(\n",
    "                    df_ego.groupby('burst')['nodes'].apply(lambda x: (float(len(set(x))), float(len(list(x))))).values)\n",
    "                dt_dictionary[k]['n_link_cnt'].update(cnt_n_links_per_train)\n",
    "\n",
    "        # Store the results in the overall dictionary\n",
    "        for k in graph_list:\n",
    "            if include_single_link_burst:\n",
    "                overall_dictionary[k]['burst_cnt_link'][dt] = dt_dictionary[k]['burst_cnt_link']\n",
    "            overall_dictionary[k]['burst_cnt_ego'][dt] = dt_dictionary[k]['burst_cnt_ego']\n",
    "            overall_dictionary[k]['n_link_cnt'][dt] = dt_dictionary[k]['n_link_cnt']\n",
    "\n",
    "        # If reproducing the paper, save the results to files\n",
    "        if reproduce_paper:\n",
    "            if graph_list == ['G']:\n",
    "                file_2_save = [overall_dictionary[k]['burst_cnt_link'][dt], overall_dictionary[k]['burst_cnt_ego'][dt],\n",
    "                               Counter(), Counter(), Counter(), Counter()]\n",
    "                file_2_save_link = [overall_dictionary[k]['n_link_cnt'][dt], Counter(), Counter(), Counter()]\n",
    "\n",
    "                try:\n",
    "                    os.mkdir('../Results/Bursty_trains/' + title1 + '/')\n",
    "                except:\n",
    "                    print('../Results/Bursty_trains/' + title1 + '/')\n",
    "\n",
    "                title_burst_cnt = '../Results/Bursty_trains/' + title1 + '/' + title1 + '_' + str(dt)\n",
    "                assert file_2_save[:2] == joblib.load(title_burst_cnt + '.joblib')[:2]\n",
    "\n",
    "                title_link_cnt = '../Results/Bursty_trains/' + title1 + '/' + title1 + '_n_links_' + str(dt)\n",
    "                assert file_2_save_link[0] == joblib.load(title_link_cnt + '.joblib')[0]\n",
    "\n",
    "            elif graph_list == ['G1', 'G2', 'G3']:\n",
    "                # The order of the list is weird, but this is the same as the code used for computing results in the paper.\n",
    "                # It's present only in the option to reproduce the paper.\n",
    "                file_2_save = [overall_dictionary['G2']['burst_cnt_ego'][dt], overall_dictionary['G1']['burst_cnt_link'][dt],\n",
    "                               overall_dictionary['G1']['burst_cnt_ego'][dt], overall_dictionary['G3']['burst_cnt_ego'][dt]]\n",
    "                file_2_save_link = [overall_dictionary['G2']['n_link_cnt'][dt], overall_dictionary['G1']['n_link_cnt'][dt],\n",
    "                                    overall_dictionary['G3']['n_link_cnt'][dt]]\n",
    "\n",
    "                try:\n",
    "                    os.mkdir('../Results/Bursty_trains/' + title1 + 'rand/')\n",
    "                except:\n",
    "                    print('../Results/Bursty_trains/' + title1 + 'rand/')\n",
    "\n",
    "                title_burst_cnt = '../Results/Bursty_trains/' + title1 + 'rand/' + title1 + '_' + str(dt) + '_' + str(seed)\n",
    "                assert file_2_save == joblib.load(title_burst_cnt + '.joblib')\n",
    "\n",
    "                title_link_cnt = '../Results/Bursty_trains/' + title1 + 'rand/' + title1 + '_n_links_' + str(dt) + '_' + str(seed)\n",
    "                assert file_2_save_link == joblib.load(title_link_cnt + '.joblib')\n",
    "\n",
    "    return overall_dictionary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Trains for time series of activity of top 10% most active links for Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def compute_bursty_trains_most_active(df,line_graph,dt_list,title1,most_active = 0.1): \n",
    "    for dt in dt_list:\n",
    "\n",
    "        cnt_tot = {}\n",
    "        link_cnt_tot = {}\n",
    "        most_active_links = df.groupby(df.nodes).size().sort_values(ascending = False)[:int(float(len(g.nodes))*most_active)].index\n",
    "        link_weights = df.groupby(df.nodes).size()\n",
    "        ### include all links with weight w>=w_min\n",
    "        w_min = link_weights.sort_values(ascending = False)[:int(float(len(g.nodes))*0.1)].iloc[-1]\n",
    "        most_active_links = node_rank[node_rank>=minimum_value].index\n",
    "\n",
    "\n",
    "        cnt_n = Counter()\n",
    "        cnt1_n_links = Counter()\n",
    "\n",
    "\n",
    "\n",
    "        k = 0\n",
    "        for nodes in tqdm(most_active_links):\n",
    "\n",
    "\n",
    "            df_rest_most_active_links = df[df.nodes == nodes]   \n",
    "\n",
    "\n",
    "            brst_cnt_most_active_links,df_rest_most_active_links = get_burst_train(df_rest_most_active_links,dt)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            cnt_n.update(brst_cnt_neigh)               ### data\n",
    "\n",
    "\n",
    "\n",
    "        cnt_tot[title1] = cnt_n\n",
    "        try:os.mkdir('../Results/Bursty_trains_most_active/')\n",
    "        except: print 'folder already existing'\n",
    "        #assert cnt_tot == joblib.load('../Results/Bursty_trains_most_active/'+title1+'_'+str(dt)+'.joblib')       \n",
    "        joblib.dump(cnt_tot,'../Results/Bursty_trains_most_active/'+title1+'_'+str(dt)+'.joblib')       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "seed = 1\n",
    "dt_list = [60]\n",
    "print seed\n",
    "\n",
    "\n",
    "title1 = 'tij_lnVS'\n",
    "df = get_df(title1)\n",
    "g = get_linegraph(title1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/755 [00:00<?, ?it/s]/Users/albertoceria/anaconda/lib/python2.7/site-packages/ipykernel_launcher.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "100%|██████████| 755/755 [01:33<00:00,  8.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Results/Bursty_trains/tij_lnVS/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/755 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 755/755 [05:17<00:00,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Results/Bursty_trains/tij_lnVSrand/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cc = compute_bursty_trains(df,g,dt_list,['G'],seed,title1,include_single_link_burst = True, reproduce_paper = True)\n",
    "\n",
    "dd = compute_bursty_trains(df,g,dt_list,['G1','G2','G3'],seed,title1,include_single_link_burst = True, reproduce_paper = True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
