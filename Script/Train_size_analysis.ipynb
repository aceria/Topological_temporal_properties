{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bursty Train Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "#-----------------------------IMPORTANT-------------------------------------------\n",
    "### VERY IMPORTANT: Changing the path from library to library2 change the folder of original results\n",
    "import sys\n",
    "sys.path.insert(0, '../Script/library3/')\n",
    "\n",
    "from utilities import *\n",
    "from randomization import *\n",
    "from burst_func import *\n",
    "import networkx as nx\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def burst_train(inter_ev,dt):\n",
    "    ev_distr = np.zeros(len(inter_ev))\n",
    "    i = 0\n",
    "    \n",
    "    cnt = Counter()\n",
    "    d = 0\n",
    "    c = 1\n",
    "    ev_distr[0] = d\n",
    "    while i < len(inter_ev):\n",
    "        \n",
    "        \n",
    "        if inter_ev[i]<= dt:\n",
    "            \n",
    "            ev_distr[i+1] = d\n",
    "            c+=1\n",
    "            \n",
    "            i +=1\n",
    "    \n",
    "        else:\n",
    "            \n",
    "            cnt.update(Counter([c]))\n",
    "            \n",
    "            d +=1\n",
    "            \n",
    "            if i<len(inter_ev)-1:ev_distr[i+1] = d\n",
    "            \n",
    "            i+=1\n",
    "            c = 1\n",
    "            \n",
    "            continue\n",
    "    assert (sum([k*v for k,v in cnt.items()]) == np.sum([k*v for k,v in Counter(Counter(ev_distr).values()).items()]))\n",
    "    return cnt,ev_distr\n",
    "\n",
    "\n",
    "def get_burst_train(df,dt):\n",
    "    \n",
    "    df_rest = df.copy()\n",
    "    int_ev_time = [x for x in (df_rest.timestamp.shift(-1) - df_rest.timestamp).values if ((x!= np.nan))]\n",
    "    b_train = burst_train(int_ev_time,dt)[0]\n",
    "    bursts = burst_train(int_ev_time,dt)[1]\n",
    "    df['burst'] = bursts\n",
    "    return Counter(b_train),df,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Trains of egonetwork activity timer series for Randomized reference models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bursty_trains_rand(df,line_graph,dt_list,seed,title1):\n",
    "    \n",
    "    new_burst1 = {}\n",
    "    neigh_new_burst1 = {}\n",
    "\n",
    "    rand_orig_neigh_burst1 = {}\n",
    "    rand_new_neigh_burst1 = {}\n",
    "\n",
    "\n",
    "\n",
    "    n_link_rand_orig_neigh_burst1 = {}\n",
    "    n_link_neigh_new_burst1 = {}\n",
    "    n_link_rand_new_neigh_burst1 = {}\n",
    "\n",
    "    df_new = permute_timestamps(df,seed)    ### timestamp reshuffle\n",
    "    df1 = shuffle_df(df,seed)               ### timeseries reshuffle\n",
    "    df1_n = random_df_same_weight(df,seed)  ### timeseries reshuffle with same n contacts\n",
    "    for dt in dt_list:\n",
    "\n",
    "        cnt1_s = Counter()\n",
    "\n",
    "        cnt1_n = Counter()\n",
    "        cnt_rn = Counter()\n",
    "        cnt1_rn = Counter()\n",
    "\n",
    "\n",
    "        cnt_rn_links = Counter()\n",
    "        cnt1_n_links = Counter()\n",
    "        cnt1_rn_links = Counter()\n",
    "\n",
    "        for nodes in tqdm(df_new.nodes.unique()):\n",
    "\n",
    "                neigh_set = (set(list(nx.neighbors(line_graph,nodes)))|set([nodes]))\n",
    "\n",
    "                df_rest_new = df_new[df_new.nodes == nodes]\n",
    "\n",
    "                df_rest_new_neigh = df_new[df_new.nodes.isin(neigh_set)] ### timestamp reshuffle\n",
    "                df_rest_neigh_r = df1[df1.nodes.isin(neigh_set)]   ### timeseries reshuffle\n",
    "                df_rest_new_neigh_r = df1_n[df1_n.nodes.isin(neigh_set)] ### timeseries reshuffle with same n contacts\n",
    "\n",
    "\n",
    "\n",
    "                brst_cnt_new_neigh,df_rest_new_neigh = get_burst_train(df_rest_new_neigh,dt) ### timestamp reshuffle\n",
    "                brst_cnt_neigh_r,df_rest_neigh_r = get_burst_train(df_rest_neigh_r,dt) ### timeseries reshuffle\n",
    "                brst_cnt_new_neigh_r,df_rest_new_neigh_r = get_burst_train(df_rest_new_neigh_r,dt) ### timeseries reshuffle with same n contacts\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                cnt1_s.update(get_burst_train(df_rest_new,dt=dt)[0])\n",
    "                cnt1_n.update(brst_cnt_new_neigh)    ### timestamp reshuffle\n",
    "                cnt_rn.update(brst_cnt_neigh_r)       ### timeseries reshuffle\n",
    "                cnt1_rn.update(brst_cnt_new_neigh_r)   ### timeseries reshuffle with same n contacts\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                cnt_rn_links.update((Counter(df_rest_neigh_r.groupby('burst')['nodes'].apply(lambda x:(float(len(set(x))),float(len(list(x))))).values)))\n",
    "                cnt1_n_links.update((Counter(df_rest_new_neigh.groupby('burst')['nodes'].apply(lambda x:(float(len(set(x))),float(len(list(x))))).values)))\n",
    "                cnt1_rn_links.update((Counter(df_rest_new_neigh_r.groupby('burst')['nodes'].apply(lambda x:(float(len(set(x))),float(len(list(x))))).values)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        new_burst1[title1+str(dt)] = cnt1_s\n",
    "        neigh_new_burst1[title1+str(dt)] = cnt1_n      ### timestamp reshuffle\n",
    "        rand_orig_neigh_burst1[title1+str(dt)] = cnt_rn  ### timeseries reshuffle\n",
    "        rand_new_neigh_burst1[title1+str(dt)] = cnt1_rn   ### timeseries reshuffle with same n contacts\n",
    "\n",
    "\n",
    "\n",
    "        n_link_rand_orig_neigh_burst1[title1+str(dt)] = cnt_rn_links            ### timeseries reshuffle\n",
    "        n_link_neigh_new_burst1[title1+str(dt)] = cnt1_n_links                  ### timestamp reshuffle\n",
    "        n_link_rand_new_neigh_burst1[title1+str(dt)] = cnt1_rn_links            ### timeseries reshuffle with same n contacts\n",
    "\n",
    "        ### oreder: timeseries reshuffle, single, timestamp reshuffle, timeseries reshuffle with same n contacts\n",
    "        file_2_save = map(lambda x: x[title1+str(dt)],[rand_orig_neigh_burst1,new_burst1,neigh_new_burst1,rand_new_neigh_burst1])\n",
    "        ### oreder: timeseries reshuffle, timestamp reshuffle, timeseries reshuffle with same n contacts\n",
    "        file_2_save_link = map(lambda x: x[title1+str(dt)],[n_link_rand_orig_neigh_burst1,n_link_neigh_new_burst1,n_link_rand_new_neigh_burst1])\n",
    "\n",
    "        try: os.mkdir('../Results/Bursty_trains/'+title1+'rand/')\n",
    "        except: print '../Results/Bursty_trains/'+title1+'rand/'\n",
    "       \n",
    "        a = '../Results/Bursty_trains/'+title1+'rand/'+title1+'_'+str(dt)+'_'+str(seed)\n",
    "        #assert file_2_save == joblib.load(a+'.joblib')\n",
    "        joblib.dump(file_2_save,a+'.joblib')\n",
    "\n",
    "        b = '../Results/Bursty_trains/'+title1+'rand/'+title1+'_n_links_'+str(dt)+'_'+str(seed)\n",
    "        #assert file_2_save_link == joblib.load(b+'.joblib')\n",
    "        joblib.dump(file_2_save_link,b+'.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Trains of egonetwork activity timer series for Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bursty_trains_data(df,line_graph,dt_list,title1):\n",
    "    orig_burst1 = {}\n",
    "    new_burst1 = {}\n",
    "    neigh_new_burst1 = {}\n",
    "    neigh_orig_burst1 = {}\n",
    "    rand_orig_neigh_burst1 = {}\n",
    "    rand_new_neigh_burst1 = {}\n",
    "\n",
    "    n_link_neigh_new_burst1 = {}\n",
    "    n_link_neigh_orig_burst1 = {}\n",
    "    n_link_rand_orig_neigh_burst1 = {}\n",
    "    n_link_rand_new_neigh_burst1 = {}\n",
    "    \n",
    "    #    if title1 !='tij_lnVS':continue\n",
    "    for dt in dt_list:\n",
    "        cnt_s = Counter()\n",
    "        cnt1_s = Counter()\n",
    "        cnt_n = Counter()\n",
    "        cnt1_n = Counter()\n",
    "        cnt_rn = Counter()\n",
    "        cnt1_rn = Counter()\n",
    "\n",
    "        cnt_n_links = Counter()\n",
    "        cnt_rn_links = Counter()\n",
    "        cnt1_n_links = Counter()\n",
    "        cnt1_rn_links = Counter()\n",
    "        k = 0\n",
    "        for nodes in tqdm(df.nodes.unique()):\n",
    "\n",
    "            neigh_set = (set(list(nx.neighbors(g,nodes)))|set([nodes]))\n",
    "            df_rest = df[df.nodes == nodes]\n",
    "            df_rest_neigh = df[df.nodes.isin(neigh_set)]                    ### data\n",
    "\n",
    "\n",
    "\n",
    "            brst_cnt_neigh,df_rest_neigh = get_burst_train(df_rest_neigh,dt)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            cnt_s.update(get_burst_train(df_rest,dt)[0])\n",
    "            cnt_n.update(brst_cnt_neigh)               ### data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            cnt_n_links.update((Counter(df_rest_neigh.groupby('burst')['nodes'].apply(lambda x:(float(len(set(x))),float(len(list(x))))).values)))\n",
    "\n",
    "\n",
    "\n",
    "            k += 1\n",
    "\n",
    "        orig_burst1[title1+str(dt)] = cnt_s\n",
    "        new_burst1[title1+str(dt)] = cnt1_s\n",
    "        neigh_new_burst1[title1+str(dt)] = cnt1_n         ### permute timestamps\n",
    "        neigh_orig_burst1[title1+str(dt)] = cnt_n         ### data\n",
    "        rand_orig_neigh_burst1[title1+str(dt)] = cnt_rn   ### permute timeseries\n",
    "        rand_new_neigh_burst1[title1+str(dt)] = cnt1_rn   ### permute timeseries preserve contacts\n",
    "\n",
    "\n",
    "\n",
    "        n_link_neigh_orig_burst1[title1+str(dt)] = cnt_n_links\n",
    "        n_link_rand_orig_neigh_burst1[title1+str(dt)] = cnt_rn_links\n",
    "        n_link_neigh_new_burst1[title1+str(dt)] = cnt1_n_links\n",
    "        n_link_rand_new_neigh_burst1[title1+str(dt)] = cnt1_rn_links\n",
    "\n",
    "\n",
    "        file_2_save = map(lambda x: x[title1+str(dt)],[orig_burst1,neigh_orig_burst1,rand_orig_neigh_burst1,new_burst1,neigh_new_burst1,rand_new_neigh_burst1])\n",
    "        file_2_save_link = map(lambda x: x[title1+str(dt)],[n_link_neigh_orig_burst1,n_link_rand_orig_neigh_burst1,n_link_neigh_new_burst1,n_link_rand_new_neigh_burst1])\n",
    "\n",
    "\n",
    "        try: os.mkdir('../Results/Bursty_trains/'+title1+'/')\n",
    "        except: print '../Results/Bursty_trains/'+title1+'/'\n",
    "       \n",
    "        a = '../Results/Bursty_trains/'+title1+'/'+title1+'_'+str(dt)\n",
    "        #assert file_2_save == joblib.load(a+'.joblib')\n",
    "        joblib.dump(file_2_save,a+'.joblib')\n",
    "\n",
    "        b = '../Results/Bursty_trains/'+title1+'/'+title1+'_n_links_'+str(dt)\n",
    "        #assert file_2_save_link == joblib.load(b+'.joblib')\n",
    "        joblib.dump(file_2_save_link,b+'.joblib')\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Trains for time series of activity of top 10% most active links for Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_bursty_trains_most_active(df,line_graph,dt_list,title1): \n",
    "    for dt in [60,120,300,600,1200,2400,3600]:\n",
    "\n",
    "        cnt_tot = {}\n",
    "        link_cnt_tot = {}\n",
    "\n",
    "    #    if title1 !='tij_lnVS': continue\n",
    "    #     if title1 in rand_new_neigh_burst1.keys():continue\n",
    "            #node_list = list(g.nodes)\n",
    "        node_list1 = df.groupby(df.nodes).size().sort_values(ascending = False)[:int(float(len(g.nodes))*0.1)].index\n",
    "        node_rank = df.groupby(df.nodes).size()\n",
    "        minimum_value = node_rank.sort_values(ascending = False)[:int(float(len(g.nodes))*0.1)].iloc[-1]\n",
    "        node_list2 = node_rank[node_rank>=minimum_value].index\n",
    "\n",
    "        df_list = list()\n",
    "\n",
    "        cnt_n = Counter()\n",
    "        cnt1_n_links = Counter()\n",
    "\n",
    "\n",
    "\n",
    "        k = 0\n",
    "        for nodes in tqdm(node_list2):\n",
    "\n",
    "\n",
    "            df_rest_neigh = df[df.nodes == nodes]   \n",
    "\n",
    "\n",
    "            brst_cnt_neigh,df_rest_neigh = get_burst_train(df_rest_neigh,dt)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            cnt_n.update(brst_cnt_neigh)               ### data\n",
    "\n",
    "\n",
    "\n",
    "        cnt_tot[title1] = cnt_n\n",
    "        try:os.mkdir('../Results/Bursty_trains_most_active/')\n",
    "        except: print 'folder already existing'\n",
    "        #assert cnt_tot == joblib.load('../Results/Bursty_trains_most_active/'+title1+'_'+str(dt)+'.joblib')       \n",
    "        joblib.dump(cnt_tot,'../Results/Bursty_trains_most_active/'+title1+'_'+str(dt)+'.joblib')       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "seed = 1\n",
    "dt_list = [60,120,300,600,1200,2400,3600]\n",
    "print seed\n",
    "\n",
    "\n",
    "title1 = 'tij_lnVS'\n",
    "df = get_df(title1)\n",
    "g = get_linegraph(title1)\n",
    "    \n",
    "compute_bursty_trains_rand(df,g,dt_list,seed,title1)\n",
    "\n",
    "compute_bursty_trains_data(df,g,dt_list,title1)\n",
    "\n",
    "compute_bursty_trains_most_active(df,g,dt_list,title1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
